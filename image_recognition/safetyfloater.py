# -*- coding: utf-8 -*-
"""SafetyFloater

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KgdHkaarqFiVuq4E2555Y-TesA1CqN5f

#Import of libraries and setup of the Colab's GPU
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import keras
from keras.preprocessing.image import ImageDataGenerator
print("Tensorflow version %s" %tf.__version__)

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

"""##Loading Data and creation of train and test set


"""

import os
from google.colab import drive
drive.mount('/content/drive')
datadir = '/content/drive/MyDrive/Colab Notebooks/safety_data'
data_train = datadir+'/train/'
data_test = datadir+'/test/'
batch_size = 32

image_size=(128,128)

datagen_test = ImageDataGenerator(
    rescale = 1. / 255,)

  
datagen_train = ImageDataGenerator(rescale = 1. / 255 )

X_train=datagen_train.flow_from_directory(
    directory=data_train,\
    target_size=image_size,\
    color_mode="rgb",\
    batch_size=batch_size,\
    class_mode="categorical",
    shuffle=True)


X_test = datagen_test.flow_from_directory(
    directory=data_test,
    target_size=image_size,
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="categorical",
    shuffle=True)


num_samples = X_train.n
num_classes = X_train.num_classes
input_shape = X_train.image_shape

num_samples_test = X_test.n
num_classes_test = X_test.num_classes
input_shape_test = X_test.image_shape

classnames = [k for k,v in X_train.class_indices.items()]
print("\n\n")

print("Image input %s" %str(input_shape))
print("Classes: %r" %classnames)
print('Loaded %d training samples from %d classes.' %(num_samples,num_classes))
print("\n")

print("Image input %s TEST" %str(input_shape_test))
print('Loaded %d training samples from %d classes. TEST' %(num_samples_test,num_classes_test))
print(image_size)

"""## Show random samples"""

print("TRAIN \n")
n = 3
x,y = X_train.next()
# x,y size is train_generator.batch_size

for i in range(0,n):
    image = x[i]
    label = y[i].argmax()  # categorical from one-hot-encoding
    print(classnames[label])
    plt.imshow(image)
    plt.show()

print("TEST \n")
x_test,y_test = X_test.next()
# x,y size is train_generator.batch_size

for i in range(0,n):
    image = x_test[i]
    label = y_test[i].argmax()  # categorical from one-hot-encoding
    print(classnames[label])
    plt.imshow(image)
    plt.show()

"""## MR-SSD for ship classification used with SAR images attempt do adopt their structure"""

from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras import regularizers
from keras import optimizers

def MR_SSD(input_shape, num_classes, regl2 = 0.001, lr=0.0001):

    model = Sequential()

    # C1 Convolutional Layer 
    model.add(Conv2D(filters=32, input_shape=input_shape, kernel_size=(6,6),strides=(1,1), padding='valid'))
    model.add(Activation('relu'))
    # Pooling 1
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2), padding='valid'))
   
    # C2 Convolutional Layer
    model.add(Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), padding='valid'))
    model.add(Activation('relu'))
    # Pooling 2
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2), padding='valid'))
    
    # C3 Convolutional Layer
    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid'))
    model.add(Activation('relu'))

    # C4 Convolutional Layer
    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid'))
    model.add(Activation('relu'))
    
    # C5 Convolutional Layer
    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid'))
    model.add(Activation('relu'))
    
    # C6 Convolutional Layer
    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid'))
    model.add(Activation('relu'))
    
    # Pooling 3
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2), padding='valid'))
    
    # Flatten
    model.add(Flatten())

    flatten_shape = (input_shape[0]*input_shape[1]*input_shape[2],)
    
    # D1 Dense Layer
    model.add(Dense(1024, input_shape=flatten_shape, kernel_regularizer=regularizers.l2(regl2)))
    model.add(Activation('relu'))
   
    # D2 Dense Layer
    model.add(Dense(1024, kernel_regularizer=regularizers.l2(regl2)))
    model.add(Activation('relu'))
    # Dropout
    model.add(Dropout(0.8))
    # Batch Normalisation
    model.add(BatchNormalization())

    # Output Layer
    model.add(Dense(num_classes))
    model.add(Activation('softmax'))

    # Compile

    adam = optimizers.Adam(lr=lr)
    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])
    print("MR-SSD -> ADAM")
    
    return model
 

model = MR_SSD(input_shape,num_classes)
model.summary()

"""##Train with early stopping"""

from keras import callbacks
from keras.callbacks import ModelCheckpoint
#We define the early stopping using as metric the validation accuracy with a patience equals to 5
stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=5)

#We define the callback ModelCheckpoint in order to save the best model during the training phase
models_dir ="/content/drive/MyDrive/MR-SSD-{epoch:02d}-{val_accuracy:.2f}.h5"
checkpoint=ModelCheckpoint(models_dir,monitor="val_accuracy",verbose=1,save_best_only=True,mode="max")
callback_list=[checkpoint,stopping]

#We define the number of epochs and other utilities variables
steps_per_epoch = X_train.n//X_train.batch_size
val_steps = X_test.n//X_test.batch_size+1
epochs = 100

try:
    history = model.fit(X_train, epochs=epochs, verbose=1,\
                    steps_per_epoch=steps_per_epoch,\
                    validation_data=X_test,\
                    validation_steps=val_steps,\
                    callbacks=callback_list)
except KeyboardInterrupt:
    pass

"""##Precision and recall"""

#Sklearn functions
import sklearn.metrics 
from sklearn.utils.multiclass import unique_labels
from sklearn.metrics import classification_report, confusion_matrix

preds = model.predict(X_test,verbose=1,steps=val_steps)

Ypred = np.argmax(preds, axis=1)
Ytest = X_test.classes  

print(classification_report(Ytest, Ypred, labels=None, target_names=classnames, digits=3))

"""## CONFUSION MATRIX"""

cm = confusion_matrix(Ytest, Ypred, labels=None, sample_weight=None)
#print(cm)

import numpy as np


def plot_confusion_matrix(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=True):
    import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")


    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.show()

plot_confusion_matrix(cm, normalize    = False,
                      target_names = classnames,
                      title        = "Confusion Matrix")

"""##PLOTS"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""##Save history"""

#Various functions
from PIL import Image
import pickle
from matplotlib import pyplot
from IPython.display import clear_output
def savehistory(history,problem):
    results_dir="/content/drive/MyDrive/"
    filename = os.path.join(results_dir, '%s.hist' %problem)
    with open(filename, 'wb') as f:
        pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)
    print("\nHystory saved on file %s\n" %filename)


savehistory(history,"MR-SSD-history")